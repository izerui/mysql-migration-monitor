#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•ç‰ˆæœ¬çš„MySQLè¿ç§»ç›‘æ§å·¥å…·
æ·»åŠ è¯¦ç»†çš„æ—¥å¿—è¾“å‡ºï¼Œå¸®åŠ©å®šä½æ•°æ®æ˜¾ç¤ºé—®é¢˜
"""

import asyncio
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

import aiomysql
import configparser
from config_models import MySQLConfig, GlobConfig
from data_access.mysql_repository import MySQLRepository
from data_access.table_service import TableInfo, TableDataService


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('debug_monitor.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class DebugMySQLRepository(MySQLRepository):
    """è°ƒè¯•ç‰ˆæœ¬çš„MySQLä»“åº“ï¼Œæ·»åŠ è¯¦ç»†æ—¥å¿—"""

    async def connect(self, database: str) -> Optional[aiomysql.Connection]:
        """è¿æ¥MySQLæ•°æ®åº“ï¼ˆå¸¦è°ƒè¯•ä¿¡æ¯ï¼‰"""
        logger.info(f"å°è¯•è¿æ¥æ•°æ®åº“: {self.config.host}:{self.config.port}/{database}")
        conn = await super().connect(database)
        if conn:
            logger.info(f"âœ… æˆåŠŸè¿æ¥æ•°æ®åº“: {database}")
        else:
            logger.error(f"âŒ è¿æ¥æ•°æ®åº“å¤±è´¥: {database}")
        return conn

    async def get_table_rows_count(self, conn: aiomysql.Connection, schema_name: str, table_name: str) -> int:
        """è·å–è¡¨çš„ç²¾ç¡®è¡Œæ•°ï¼ˆå¸¦è°ƒè¯•ä¿¡æ¯ï¼‰"""
        logger.debug(f"å¼€å§‹æŸ¥è¯¢è¡¨è¡Œæ•°: {schema_name}.{table_name}")
        try:
            result = await super().get_table_rows_count(conn, schema_name, table_name)
            logger.debug(f"æŸ¥è¯¢ç»“æœ: {schema_name}.{table_name} = {result} è¡Œ")
            return result
        except Exception as e:
            logger.error(f"æŸ¥è¯¢è¡¨è¡Œæ•°å¤±è´¥: {schema_name}.{table_name} - {str(e)}")
            return -1

    async def get_tables_from_schema(self, conn: aiomysql.Connection, schema_name: str) -> List[str]:
        """è·å–æŒ‡å®šschemaä¸­çš„æ‰€æœ‰è¡¨åï¼ˆå¸¦è°ƒè¯•ä¿¡æ¯ï¼‰"""
        logger.info(f"è·å–schemaä¸­çš„è¡¨åˆ—è¡¨: {schema_name}")
        tables = await super().get_tables_from_schema(conn, schema_name)
        logger.info(f"schema {schema_name} ä¸­æ‰¾åˆ° {len(tables)} ä¸ªè¡¨: {tables[:10]}...")
        return tables


class DebugTableDataService(TableDataService):
    """è°ƒè¯•ç‰ˆæœ¬çš„è¡¨æ•°æ®æœåŠ¡"""

    async def initialize_tables(self, schema_names: List[str]) -> Dict[str, Dict[str, TableInfo]]:
        """åˆå§‹åŒ–è¡¨ç»“æ„ï¼ˆå¸¦è°ƒè¯•ä¿¡æ¯ï¼‰"""
        logger.info(f"å¼€å§‹åˆå§‹åŒ–è¡¨ç»“æ„ï¼Œæ•°æ®åº“åˆ—è¡¨: {schema_names}")
        result = await super().initialize_tables(schema_names)

        total_tables = sum(len(tables) for tables in result.values())
        logger.info(f"åˆå§‹åŒ–å®Œæˆï¼Œå…±å‘ç° {total_tables} ä¸ªè¡¨")

        for schema_name, tables in result.items():
            logger.info(f"  {schema_name}: {len(tables)} ä¸ªè¡¨")
            for table_name, table_info in tables.items():
                logger.debug(f"    {table_name}: {table_info.full_name()}")

        return result

    async def update_source_schema_tables(self, schema_name: str, tables_dict: Dict[str, TableInfo], use_estimation: bool = False) -> bool:
        """æ›´æ–°æºè¡¨è®°å½•æ•°ï¼ˆå¸¦è°ƒè¯•ä¿¡æ¯ï¼‰"""
        logger.info(f"å¼€å§‹æ›´æ–°æºè¡¨è®°å½•æ•°: schema={schema_name}, è¡¨æ•°é‡={len(tables_dict)}, use_estimation={use_estimation}")
        result = await super().update_source_schema_tables(schema_name, tables_dict, use_estimation)
        logger.info(f"æºè¡¨æ›´æ–°å®Œæˆ: schema={schema_name}, ç»“æœ={result}")

        # è®°å½•æ¯ä¸ªè¡¨çš„è®°å½•æ•°
        for table_name, table_info in tables_dict.items():
            logger.debug(f"  {table_name}: source_rows={table_info.source_rows}")

        return result

    async def update_target_schema_tables(self, schema_name: str, tables_dict: Dict[str, TableInfo], use_estimation: bool = False) -> bool:
        """æ›´æ–°ç›®æ ‡è¡¨è®°å½•æ•°ï¼ˆå¸¦è°ƒè¯•ä¿¡æ¯ï¼‰"""
        logger.info(f"å¼€å§‹æ›´æ–°ç›®æ ‡è¡¨è®°å½•æ•°: schema={schema_name}, è¡¨æ•°é‡={len(tables_dict)}, use_estimation={use_estimation}")
        result = await super().update_target_schema_tables(schema_name, tables_dict, use_estimation)
        logger.info(f"ç›®æ ‡è¡¨æ›´æ–°å®Œæˆ: schema={schema_name}, ç»“æœ={result}")

        # è®°å½•æ¯ä¸ªè¡¨çš„è®°å½•æ•°
        for table_name, table_info in tables_dict.items():
            logger.debug(f"  {table_name}: target_rows={table_info.target_rows}")

        return result


class DebugMonitor:
    """è°ƒè¯•ç‰ˆæœ¬çš„ç›‘æ§å™¨"""

    def __init__(self, config_file: str = "config.ini"):
        self.config_file = config_file
        self.source_config: Optional[MySQLConfig] = None
        self.target_config: Optional[MySQLConfig] = None
        self.global_config: Optional[GlobConfig] = None
        self.table_data_service: Optional[DebugTableDataService] = None
        self.schema_tables: Dict[str, Dict[str, TableInfo]] = {}
        self.tables: List[TableInfo] = []

    async def load_config(self) -> bool:
        """åŠ è½½é…ç½®ï¼ˆå¸¦è°ƒè¯•ä¿¡æ¯ï¼‰"""
        logger.info(f"å¼€å§‹åŠ è½½é…ç½®æ–‡ä»¶: {self.config_file}")

        config_path = Path(self.config_file)
        if not config_path.exists():
            logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return False

        try:
            config = configparser.ConfigParser()
            config.read(config_path, encoding='utf-8')

            # è¯»å–å…¨å±€é…ç½®
            databases = [db.strip() for db in config['global']['databases'].split(',')]
            refresh_interval = int(config['global'].get('refresh_interval', 3))

            self.global_config = GlobConfig(
                databases=databases,
                refresh_interval=refresh_interval
            )

            # è¯»å–æºæ•°æ®åº“é…ç½®
            source_section = config['source']
            self.source_config = MySQLConfig(
                host=source_section['host'],
                port=int(source_section['port']),
                username=source_section['username'],
                password=source_section['password']
            )

            # è¯»å–ç›®æ ‡æ•°æ®åº“é…ç½®
            target_section = config['target']
            self.target_config = MySQLConfig(
                host=target_section['host'],
                port=int(target_section['port']),
                username=target_section['username'],
                password=target_section['password']
            )

            logger.info("âœ… é…ç½®åŠ è½½æˆåŠŸ")
            logger.info(f"  æ•°æ®åº“: {self.global_config.databases}")
            logger.info(f"  åˆ·æ–°é—´éš”: {self.global_config.refresh_interval}ç§’")
            logger.info(f"  æºæ•°æ®åº“: {self.source_config.host}:{self.source_config.port}")
            logger.info(f"  ç›®æ ‡æ•°æ®åº“: {self.target_config.host}:{self.target_config.port}")

            return True

        except Exception as e:
            logger.error(f"é…ç½®åŠ è½½å¤±è´¥: {str(e)}")
            return False

    async def initialize(self) -> bool:
        """åˆå§‹åŒ–ç›‘æ§ï¼ˆå¸¦è°ƒè¯•ä¿¡æ¯ï¼‰"""
        logger.info("å¼€å§‹åˆå§‹åŒ–ç›‘æ§...")

        if not await self.load_config():
            return False

        # åˆ›å»ºè°ƒè¯•ç‰ˆæœ¬çš„è¡¨æ•°æ®æœåŠ¡
        self.table_data_service = DebugTableDataService(self.source_config, self.target_config)

        # åˆå§‹åŒ–è¡¨ç»“æ„
        self.schema_tables = await self.table_data_service.initialize_tables(self.global_config.databases)

        # å±•å¹³è¡¨æ ¼åˆ—è¡¨
        self.tables = []
        for schema_tables in self.schema_tables.values():
            self.tables.extend(schema_tables.values())

        logger.info(f"åˆå§‹åŒ–å®Œæˆï¼Œå…± {len(self.tables)} ä¸ªè¡¨")
        return True

    async def run_single_update(self) -> None:
        """è¿è¡Œå•æ¬¡æ›´æ–°ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        logger.info("å¼€å§‹å•æ¬¡æ›´æ–°å¾ªç¯...")

        for schema_name, tables_dict in self.schema_tables.items():
            logger.info(f"å¤„ç†schema: {schema_name}")

            # æ›´æ–°æºè¡¨
            logger.info(f"æ›´æ–°æºè¡¨è®°å½•æ•°...")
            await self.table_data_service.update_source_schema_tables(
                schema_name, tables_dict, use_estimation=False
            )

            # æ›´æ–°ç›®æ ‡è¡¨
            logger.info(f"æ›´æ–°ç›®æ ‡è¡¨è®°å½•æ•°...")
            await self.table_data_service.update_target_schema_tables(
                schema_name, tables_dict, use_estimation=False
            )

            # æ˜¾ç¤ºç»“æœ
            logger.info(f"æ›´æ–°å®Œæˆï¼Œç»“æœ:")
            for table_name, table_info in tables_dict.items():
                logger.info(f"  {table_name}: "
                          f"æº={table_info.source_rows}, "
                          f"ç›®æ ‡={table_info.target_rows}, "
                          f"å·®å¼‚={table_info.data_diff}, "
                          f"ä¸€è‡´={table_info.is_consistent}")

    def print_summary(self) -> None:
        """æ‰“å°æ±‡æ€»ä¿¡æ¯"""
        if not self.tables:
            logger.warning("æ²¡æœ‰è¡¨æ•°æ®å¯æ˜¾ç¤º")
            return

        print("\n" + "="*80)
        print("ğŸ“Š è°ƒè¯•æ±‡æ€»æŠ¥å‘Š")
        print("="*80)

        valid_tables = [t for t in self.tables if t.target_rows != -1 and t.source_rows != -1]
        error_tables = [t for t in self.tables if t.target_rows == -1 or t.source_rows == -1]

        print(f"æ€»è¡¨æ•°: {len(self.tables)}")
        print(f"æœ‰æ•ˆè¡¨: {len(valid_tables)}")
        print(f"é”™è¯¯è¡¨: {len(error_tables)}")

        if error_tables:
            print("\nâŒ é”™è¯¯è¡¨åˆ—è¡¨:")
            for table in error_tables:
                print(f"  {table.full_name()}: "
                      f"æº={table.source_rows}, ç›®æ ‡={table.target_rows}")

        if valid_tables:
            print("\nâœ… æœ‰æ•ˆè¡¨ç»Ÿè®¡:")
            total_source = sum(t.source_rows for t in valid_tables)
            total_target = sum(t.target_rows for t in valid_tables)
            total_diff = total_target - total_source

            print(f"  æºæ€»è®°å½•æ•°: {total_source:,}")
            print(f"  ç›®æ ‡æ€»è®°å½•æ•°: {total_target:,}")
            print(f"  æ€»å·®å¼‚: {total_diff:,}")

            consistent = [t for t in valid_tables if t.is_consistent]
            inconsistent = [t for t in valid_tables if not t.is_consistent]

            print(f"  ä¸€è‡´è¡¨: {len(consistent)}")
            print(f"  ä¸ä¸€è‡´è¡¨: {len(inconsistent)}")

            if inconsistent:
                print("\nâš ï¸ ä¸ä¸€è‡´çš„è¡¨:")
                for table in sorted(inconsistent, key=lambda t: abs(t.data_diff), reverse=True)[:10]:
                    print(f"  {table.full_name()}: å·®å¼‚={table.data_diff:,}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ MySQL Migration Monitor è°ƒè¯•å·¥å…·")
    print("=" * 50)

    monitor = DebugMonitor()

    try:
        # åˆå§‹åŒ–
        if not await monitor.initialize():
            print("âŒ åˆå§‹åŒ–å¤±è´¥")
            return

        # è¿è¡Œå•æ¬¡æ›´æ–°
        await monitor.run_single_update()

        # æ‰“å°æ±‡æ€»
        monitor.print_summary()

        print("\nâœ… è°ƒè¯•å®Œæˆï¼Œè¯·æŸ¥çœ‹ debug_monitor.log è·å–è¯¦ç»†æ—¥å¿—")

    except Exception as e:
        logger.error(f"è°ƒè¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
        print(f"âŒ è°ƒè¯•å¤±è´¥: {str(e)}")
    finally:
        if monitor.table_data_service:
            await monitor.table_data_service.cancel_all_updates()


if __name__ == "__main__":
    asyncio.run(main())
