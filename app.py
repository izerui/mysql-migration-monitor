#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
MySQL vs MySQL æ•°æ®ä¸€è‡´æ€§ç›‘æ§å·¥å…· - Textualç‰ˆæœ¬ï¼ˆæ”¯æŒè¡¨æ˜ å°„å…³ç³»ï¼‰
ä½¿ç”¨Textualæ¡†æ¶æä¾›ç°ä»£åŒ–çš„TUIç•Œé¢ï¼Œæ”¯æŒDataTableæ»šåŠ¨æŸ¥çœ‹
å®æ—¶ç›‘æ§ä¸¤ä¸ªMySQLæ•°æ®åº“ä¹‹é—´çš„æ•°æ®åŒæ­¥çŠ¶æ€ï¼Œæ”¯æŒè¡¨æ˜ å°„å…³ç³»å’Œå¤šæºè¡¨åˆå¹¶åˆ°ç›®æ ‡è¡¨ã€‚
"""

import argparse
import asyncio
import re
import signal
import sys
from configparser import ConfigParser
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional

import aiomysql
from rich.text import Text
from textual.app import App, ComposeResult
from textual.containers import Container, Vertical
from textual.timer import Timer
from textual.widgets import DataTable, Footer, Header, Static


@dataclass
class DatabaseConfig:
    """æ•°æ®åº“é…ç½®"""
    host: str
    port: int
    database: str
    username: str
    password: str


@dataclass
class MySQLConfig(DatabaseConfig):
    """MySQLé…ç½®"""
    databases: List[str] = field(default_factory=list)
    ignored_prefixes: List[str] = field(default_factory=list)


@dataclass
class TableInfo:
    """è¡¨ä¿¡æ¯"""
    schema_name: str
    target_table_name: str  # ç›®æ ‡MySQLä¸­çš„è¡¨å
    target_rows: int = 0
    source_rows: int = 0
    previous_target_rows: int = 0
    previous_source_rows: int = 0
    source_tables: List[str] = field(default_factory=list)  # æºè¡¨åˆ—è¡¨
    last_updated: datetime = field(default_factory=datetime.now)
    source_last_updated: datetime = field(default_factory=datetime.now)
    target_last_updated: datetime = field(default_factory=datetime.now)
    is_first_query: bool = True
    source_updating: bool = False
    target_updating: bool = False
    target_is_estimated: bool = False
    source_is_estimated: bool = False
    pause_auto_refresh: bool = False  # æ˜¯å¦æš‚åœè‡ªåŠ¨åˆ·æ–°



    @property
    def data_diff(self) -> int:
        """æ•°æ®å·®å¼‚"""
        if self.target_rows == -1 or self.source_rows == -1:
            return 0  # é”™è¯¯çŠ¶æ€æ—¶å·®å¼‚ä¸º0ï¼Œé¿å…ç»Ÿè®¡è®¡ç®—é”™è¯¯
        return self.target_rows - self.source_rows

    @property
    def is_consistent(self) -> bool:
        """æ•°æ®æ˜¯å¦ä¸€è‡´"""
        return self.target_rows == self.source_rows

    @property
    def full_name(self) -> str:
        """å®Œæ•´è¡¨å"""
        return f"{self.schema_name}.{self.target_table_name}"


class SyncProperties:
    """è¡¨åæ˜ å°„è§„åˆ™ï¼ˆä¸Javaç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰"""

    @staticmethod
    def get_target_table_name(source_table_name: str) -> str:
        """
        ç”Ÿæˆç›®æ ‡è¡¨å
        åº”ç”¨è¡¨åæ˜ å°„è§„åˆ™ï¼štable_runtimeã€table_uuidã€table_æ•°å­— ç»Ÿä¸€æ˜ å°„åˆ° table
        """
        if not source_table_name or not source_table_name.strip():
            return source_table_name

        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸‹åˆ’çº¿
        if '_' not in source_table_name:
            return source_table_name  # æ²¡æœ‰ä¸‹åˆ’çº¿ï¼Œç›´æ¥è¿”å›

        # 1. æ£€æŸ¥ runtime åç¼€
        if source_table_name.endswith('_runtime'):
            return source_table_name[:-8]  # ç§»é™¤ "_runtime"

        # 2. æ£€æŸ¥ 9ä½æ•°å­—åç¼€
        last_underscore_index = source_table_name.rfind('_')
        if last_underscore_index > 0:
            suffix = source_table_name[last_underscore_index + 1:]
            if SyncProperties._is_numeric_suffix(suffix):
                return source_table_name[:last_underscore_index]

        # 2a. æ£€æŸ¥ 9ä½æ•°å­—_å¹´åº¦ æ ¼å¼
        # ä¾‹å¦‚: order_bom_item_333367878_2018
        if re.match(r'.*_\d{9}_\d{4}$', source_table_name):
            return re.sub(r'_\d{9}_\d{4}$', '', source_table_name)

        # 3. æ£€æŸ¥å„ç§UUIDæ ¼å¼åç¼€
        extracted_base_name = SyncProperties._extract_table_name_from_uuid(source_table_name)
        if extracted_base_name != source_table_name:
            return extracted_base_name

        # ä¸ç¬¦åˆæ˜ å°„è§„åˆ™ï¼Œä¿æŒåŸæ ·
        return source_table_name

    @staticmethod
    def _is_numeric_suffix(s: str) -> bool:
        """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä¸º9ä½çº¯æ•°å­—"""
        if not s or not s.strip():
            return False
        return re.match(r'^\d{9}$', s) is not None

    @staticmethod
    def _extract_table_name_from_uuid(table_name: str) -> str:
        """
        ä»åŒ…å«UUIDçš„è¡¨åä¸­æå–åŸºç¡€è¡¨å
        æ”¯æŒå¤šç§UUIDæ ¼å¼ï¼š
        1. order_bom_0e9b60a4_d6ed_473d_a326_9e8c8f744ec2 -> order_bom
        2. users_a1b2c3d4-e5f6-7890-abcd-ef1234567890 -> users
        3. products_a1b2c3d4e5f67890abcdef1234567890 -> products
        """
        if not table_name or '_' not in table_name:
            return table_name

        # æ¨¡å¼1: ä¸‹åˆ’çº¿åˆ†éš”çš„UUIDæ ¼å¼ (8_4_4_4_12)
        # ä¾‹å¦‚: order_bom_0e9b60a4_d6ed_473d_a326_9e8c8f744ec2
        pattern1 = r'_[0-9a-fA-F]{8}_[0-9a-fA-F]{4}_[0-9a-fA-F]{4}_[0-9a-fA-F]{4}_[0-9a-fA-F]{12}$'
        if re.search(pattern1, table_name):
            return re.sub(pattern1, '', table_name)

        # æ¨¡å¼2: è¿å­—ç¬¦åˆ†éš”çš„UUIDæ ¼å¼ (8-4-4-4-12)
        # ä¾‹å¦‚: users_a1b2c3d4-e5f6-7890-abcd-ef1234567890
        pattern2 = r'_[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$'
        if re.search(pattern2, table_name):
            return re.sub(pattern2, '', table_name)

        # æ¨¡å¼3: ä¸‹åˆ’çº¿åˆ†éš”çš„UUIDæ ¼å¼åè·Ÿå¹´åº¦ (8_4_4_4_12_å¹´åº¦)
        # ä¾‹å¦‚: order_bom_item_05355967_c503_4a2d_9dd1_2dd7a9ffa15e_2030
        pattern3 = r'_[0-9a-fA-F]{8}_[0-9a-fA-F]{4}_[0-9a-fA-F]{4}_[0-9a-fA-F]{4}_[0-9a-fA-F]{12}_\d{4}$'
        if re.search(pattern3, table_name):
            return re.sub(pattern3, '', table_name)

        # æ¨¡å¼4: æ··åˆæ ¼å¼ - ç§»é™¤æ‰€æœ‰åˆ†éš”ç¬¦åæ£€æŸ¥æ˜¯å¦ä¸º32ä½åå…­è¿›åˆ¶
        parts = table_name.split('_')
        if len(parts) >= 2:
            # ä»åå¾€å‰ç»„åˆï¼Œæ‰¾åˆ°å¯èƒ½çš„UUIDå¼€å§‹ä½ç½®
            for i in range(len(parts) - 1, 0, -1):
                possible_uuid_parts = parts[i:]
                possible_uuid = '_'.join(possible_uuid_parts)
                clean_uuid = re.sub(r'[-_]', '', possible_uuid)

                if len(clean_uuid) == 32 and re.match(r'^[0-9a-fA-F]{32}$', clean_uuid):
                    # æ‰¾åˆ°äº†UUIDï¼Œè¿”å›åŸºç¡€è¡¨å
                    return '_'.join(parts[:i])
                elif len(clean_uuid) > 32:
                    break  # å¤ªé•¿äº†ï¼Œä¸å¯èƒ½æ˜¯UUID

        return table_name  # æ²¡æœ‰æ‰¾åˆ°UUIDæ¨¡å¼ï¼Œè¿”å›åŸè¡¨å


class StatsWidget(Static):
    """ç»Ÿè®¡ä¿¡æ¯ç»„ä»¶"""

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

    def update_stats(self, tables: List[TableInfo], target_iteration: int, source_iteration: int, start_time: datetime,
                     is_paused: bool = False, sort_by: str = "schema_table", filter_mode: str = "all"):
        """æ›´æ–°ç»Ÿè®¡æ•°æ®"""
        # è¿‡æ»¤æ‰é”™è¯¯çŠ¶æ€çš„è¡¨è¿›è¡Œç»Ÿè®¡
        valid_tables = [t for t in tables if t.target_rows != -1 and t.source_rows != -1]
        error_tables = [t for t in tables if t.target_rows == -1 or t.source_rows == -1]

        total_target_rows = sum(t.target_rows for t in valid_tables)
        total_source_rows = sum(t.source_rows for t in valid_tables)
        total_diff = total_target_rows - total_source_rows

        # ä¸€è‡´æ€§ç»Ÿè®¡
        consistent_count = len([t for t in tables if t.is_consistent])
        inconsistent_count = len(tables) - consistent_count

        # è¿è¡Œæ—¶é•¿
        runtime = datetime.now() - start_time
        runtime_str = self._format_duration(runtime.total_seconds())

        # æ„å»ºæ˜¾ç¤ºæ–‡æœ¬
        text = Text()

        # æ ‡é¢˜è¡Œ
        text.append("ğŸ” MySQL vs MySQL æ•°æ®ç›‘æ§", style="bold blue")
        text.append(f" - ç›®æ ‡ç¬¬{target_iteration}æ¬¡/æºç¬¬{source_iteration}æ¬¡", style="dim")
        text.append(f" - è¿è¡Œæ—¶é•¿: {runtime_str}", style="cyan")

        # çŠ¶æ€å’Œæ’åºä¿¡æ¯
        if is_paused:
            text.append(" - ", style="dim")
            text.append("â¸ï¸ å·²æš‚åœ", style="bold yellow")

        # æ’åºå’Œè¿‡æ»¤ä¿¡æ¯
        sort_display = {
            "schema_table": "Schema.è¡¨å",
            "data_diff": "æ•°æ®å·®å¼‚",
            "target_rows": "ç›®æ ‡è®°å½•æ•°",
            "source_rows": "æºè®°å½•æ•°"
        }
        filter_display = {
            "all": "å…¨éƒ¨",
            "inconsistent": "ä¸ä¸€è‡´",
            "consistent": "ä¸€è‡´",
            "error": "é”™è¯¯"
        }
        text.append(f" - æ’åº: {sort_display.get(sort_by, sort_by)}", style="dim")
        text.append(f" - è¿‡æ»¤: {filter_display.get(filter_mode, filter_mode)}", style="dim")
        text.append(f" - æ€»è®¡: {len(tables)} ä¸ªè¡¨", style="dim")
        text.append("\n\n")

        # æ•°æ®é‡ç»Ÿè®¡
        text.append("ğŸ“ˆ æ•°æ®ç»Ÿè®¡: ", style="bold")
        text.append(f"ç›®æ ‡æ€»è®¡: {total_target_rows:,} è¡Œ, ", style="white")
        text.append(f"æºæ€»è®¡: {total_source_rows:,} è¡Œ, ", style="white")

        # æ•°æ®å·®å¼‚é¢œè‰²è¯­ä¹‰åŒ–
        if total_diff < 0:
            text.append(f"æ•°æ®å·®å¼‚: {total_diff:+,} è¡Œ", style="bold red")
        elif total_diff > 0:
            text.append(f"æ•°æ®å·®å¼‚: {total_diff:+,} è¡Œ", style="bold green")
        else:
            text.append(f"æ•°æ®å·®å¼‚: {total_diff:+,} è¡Œ", style="white")
        text.append("\n")

        # ä¸€è‡´æ€§ç»Ÿè®¡
        text.append(f"ä¸€è‡´æ€§: {consistent_count} ä¸ªä¸€è‡´", style="bold green")

        if inconsistent_count > 0:
            text.append(f", {inconsistent_count} ä¸ªä¸ä¸€è‡´", style="bold red")
        if len(error_tables) > 0:
            text.append(f", {len(error_tables)} ä¸ªé”™è¯¯", style="bold red")

        text.append("\n")

        # è¿›åº¦ä¿¡æ¯å’ŒåŒæ­¥é€Ÿåº¦ - å¸¦è¿›åº¦æ¡å’Œé€Ÿåº¦ä¼°ç®—
        if total_source_rows > 0:
            completion_rate = min(total_target_rows / total_source_rows, 1.0)
            completion_percent = completion_rate * 100

            text.append("ğŸ“Š åŒæ­¥è¿›åº¦: ", style="bold cyan")

            # åˆ›å»ºè¿›åº¦æ¡
            bar_width = 20
            filled_width = int(bar_width * completion_rate)
            empty_width = bar_width - filled_width

            # è¿›åº¦æ¡é¢œè‰²æ ¹æ®å®Œæˆç‡
            if completion_rate >= 0.95:
                bar_color = "bold green"
            elif completion_rate >= 0.8:
                bar_color = "bold yellow"
            else:
                bar_color = "bold red"

            # æ˜¾ç¤ºè¿›åº¦æ¡
            text.append("â–ˆ" * filled_width, style=bar_color)
            text.append("â–‘" * empty_width, style="dim")
            text.append(f" {completion_percent:.1f}%", style="bold white")
            text.append(f" ({total_target_rows:,}/{total_source_rows:,})", style="dim")

            if completion_rate >= 1.0:
                text.append(" - å·²å®Œæˆ", style="bold green")
            else:
                remaining = total_source_rows - total_target_rows
                text.append(f" - å‰©ä½™: {remaining:,} è¡Œ", style="dim")



        self.update(text)

    def _format_duration(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é•¿æ˜¾ç¤º"""
        if seconds < 60:
            return f"{int(seconds)}ç§’"
        elif seconds < 3600:
            minutes = int(seconds // 60)
            secs = int(seconds % 60)
            return f"{minutes}åˆ†{secs}ç§’"
        elif seconds < 86400:
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ"
        else:
            days = int(seconds // 86400)
            hours = int((seconds % 86400) // 3600)
            return f"{days}å¤©{hours}å°æ—¶"


class MonitorApp(App[None]):
    """ç›‘æ§åº”ç”¨ä¸»ç±»"""

    CSS = """
    Screen {
        background: $surface;
    }

    .stats {
        height: 10;
        border: solid $primary;
        margin: 1;
        padding: 1;
        background: $surface;
    }

    .data-table {
        height: 1fr;
        border: solid $primary;
        margin: 1;
        background: $surface;
    }

    .data-table > DataTable {
        background: $surface;
        scrollbar-background: $surface;
        scrollbar-color: $primary;
        scrollbar-corner-color: $surface;
    }

    DataTable > .datatable--cursor {
        background: $accent 50%;
    }

    DataTable > .datatable--hover {
        background: $primary 20%;
    }
    """

    BINDINGS = [
        ("q", "quit", "é€€å‡º"),
        ("r", "refresh", "æ‰‹åŠ¨åˆ·æ–°"),
        ("space", "toggle_pause", "æš‚åœ/ç»§ç»­"),
        ("s", "sort_toggle", "åˆ‡æ¢æ’åº"),
        ("f", "filter_toggle", "åˆ‡æ¢è¿‡æ»¤"),
        ("ctrl+c", "quit", "é€€å‡º"),
    ]

    def __init__(self, config_file: str = "config.ini", override_databases: Optional[List[str]] = None):
        super().__init__()
        self.config_file = config_file
        self.override_databases = override_databases
        self.source_config = None
        self.target_config = None
        self.monitor_config = {}
        self.tables: List[TableInfo] = []
        self.sync_props = SyncProperties()
        self.start_time = datetime.now()

        # åˆ†ç¦»çš„æ›´æ–°è®¡æ•°å™¨
        self.target_iteration = 0
        self.source_iteration = 0
        self.source_update_interval = 5
        self.first_source_update = True
        self.first_target_update = True
        self.target_updating = False
        self.source_updating = False

        # åœæ­¢æ ‡å¿—ï¼Œç”¨äºä¼˜é›…é€€å‡º
        self.stop_event = asyncio.Event()

        # å¼‚æ­¥æ›´æ–°æ”¯æŒ
        self.source_update_lock = asyncio.Lock()
        self.source_update_tasks = []
        self.target_update_lock = asyncio.Lock()
        self.target_update_tasks = []

        # è¿›åº¦è·Ÿè¸ª
        self.history_data = []
        self.max_history_points = 20

        # å®šæ—¶å™¨
        self.refresh_timer: Optional[Timer] = None

        # ç•Œé¢æ§åˆ¶å±æ€§
        self.is_paused = False
        self.sort_by = "schema_table"  # å¯é€‰: schema_table, data_diff, target_rows, source_rows
        self.filter_mode = "all"  # å¯é€‰: all, inconsistent, consistent, error

        # ç”¨äºå¢é‡æ›´æ–°çš„æ•°æ®ç¼“å­˜
        self._last_tables_hash = None
        self._last_display_data = {}

        # ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)

    def compose(self) -> ComposeResult:
        """æ„å»ºUIç»„ä»¶"""
        yield Header()

        with Vertical():
            # ç»Ÿè®¡ä¿¡æ¯é¢æ¿
            stats_widget = StatsWidget(classes="stats")
            stats_widget.parent_app = self  # ä¼ é€’appå®ä¾‹å¼•ç”¨
            yield stats_widget

            # æ•°æ®è¡¨æ ¼å®¹å™¨
            with Container(classes="data-table"):
                yield DataTable(id="tables")

        yield Footer()

    def on_mount(self) -> None:
        """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
        # è®¾ç½®æ•°æ®è¡¨æ ¼
        table = self.query_one("#tables", DataTable)
        table.add_columns(
            "åºå·", "SCHEMA", "ç›®æ ‡è¡¨å", "çŠ¶æ€", "ç›®æ ‡è¡Œæ•°",
            "æºæ±‡æ€»æ•°", "æ•°æ®å·®å¼‚", "ç›®æ ‡æ›´æ–°", "æºæ›´æ–°", "æºè¡¨æ•°é‡"
        )

        # å¯åŠ¨ç›‘æ§ä»»åŠ¡
        self.call_later(self.start_monitoring)

    async def start_monitoring(self):
        """å¯åŠ¨ç›‘æ§ä»»åŠ¡"""
        if not await self.load_config():
            self.exit(1)
            return

        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æµ‹è¯•
        target_conn = await self.connect_target(self.monitor_config['databases'][0])
        if not target_conn:
            self.exit(1)
            return
        if target_conn:
            target_conn.close()

        # åˆå§‹åŒ–è¡¨ç»“æ„ï¼ˆä»¥ç›®æ ‡æ•°æ®åº“ä¸ºå‡†ï¼‰
        target_tables = await self.initialize_tables_from_target()
        total_tables = sum(len(tables_dict) for tables_dict in target_tables.values())

        if total_tables == 0:
            self.exit(1)
            return

        # ç¬¬ä¸€æ¬¡æ•°æ®æ›´æ–°
        target_conn = await self.connect_target(self.monitor_config['databases'][0])
        if target_conn:
            await self.get_target_rows_from_information_schema(target_conn, target_tables)
            if target_conn is not None and hasattr(target_conn, 'closed') and not target_conn.closed:
                try:
                    await target_conn.close()
                except Exception as e:
                    print(f"å…³é—­è¿æ¥æ—¶å‡ºé”™: {e}")
            self.first_target_update = False

        # é¦–æ¬¡è·å–æºè¡¨ä¼°ç®—å€¼
        source_conn = await self.connect_source(self.monitor_config['databases'][0])
        if source_conn:
            await self.get_source_rows_from_information_schema(source_conn, target_tables)
            if source_conn is not None and hasattr(source_conn, 'closed') and not source_conn.closed:
                try:
                    await source_conn.close()
                except Exception as e:
                    print(f"å…³é—­æºè¿æ¥æ—¶å‡ºé”™: {e}")
            self.first_source_update = False

        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        self.tables = []
        for schema_name, tables_dict in target_tables.items():
            for table_info in tables_dict.values():
                self.tables.append(table_info)

        # æ›´æ–°æ˜¾ç¤º
        self.update_display()

        # å¯åŠ¨å®šæ—¶åˆ·æ–°
        refresh_interval = self.monitor_config.get('refresh_interval', 2)
        self.refresh_timer = self.set_interval(refresh_interval, self.refresh_data)

    def update_display(self):
        """æ›´æ–°æ˜¾ç¤ºå†…å®¹"""
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        stats_widget = self.query_one(StatsWidget)
        stats_widget.update_stats(
            self.tables,
            self.target_iteration,
            self.source_iteration,
            self.start_time,
            self.is_paused,
            self.sort_by,
            self.filter_mode
        )

        # æ›´æ–°æ•°æ®è¡¨æ ¼
        self._update_data_table()

    def _filter_tables(self, tables: List[TableInfo]) -> List[TableInfo]:
        """æ ¹æ®å½“å‰è¿‡æ»¤æ¨¡å¼è¿‡æ»¤è¡¨æ ¼"""
        if self.filter_mode == "inconsistent":
            return [t for t in tables if not t.is_consistent]
        elif self.filter_mode == "consistent":
            return [t for t in tables if t.is_consistent]
        elif self.filter_mode == "error":
            return [t for t in tables if t.target_rows == -1 or t.source_rows == -1]
        else:  # all
            return tables

    def _sort_tables(self, tables: List[TableInfo]) -> List[TableInfo]:
        """æ ¹æ®å½“å‰æ’åºæ–¹å¼å¯¹è¡¨æ ¼è¿›è¡Œæ’åº"""
        if self.sort_by == "data_diff":
            # æŒ‰æ•°æ®å·®å¼‚æ’åºï¼Œå·®å¼‚å¤§çš„åœ¨å‰
            return sorted(tables, key=lambda t: abs(t.data_diff) if t.data_diff != 0 else -1, reverse=True)
        elif self.sort_by == "target_rows":
            # æŒ‰ç›®æ ‡è®°å½•æ•°æ’åºï¼Œå¤šçš„åœ¨å‰
            return sorted(tables, key=lambda t: t.target_rows if t.target_rows != -1 else -1, reverse=True)
        elif self.sort_by == "source_rows":
            # æŒ‰æºè®°å½•æ•°æ’åºï¼Œå¤šçš„åœ¨å‰
            return sorted(tables, key=lambda t: t.source_rows if t.source_rows != -1 else -1, reverse=True)
        else:  # schema_table
            # æŒ‰schemaåå’Œè¡¨åæ’åº
            return sorted(tables, key=lambda t: (t.schema_name, t.target_table_name))

    def _update_data_table(self):
        """æ›´æ–°æ•°æ®è¡¨æ ¼ - ä½¿ç”¨ä¼˜åŒ–çš„é‡å»ºç­–ç•¥é¿å…æ»šåŠ¨ä½ç½®ä¸¢å¤±"""
        table = self.query_one("#tables", DataTable)

        # å…ˆè¿‡æ»¤å†æ’åº
        filtered_tables = self._filter_tables(self.tables)
        sorted_tables = self._sort_tables(filtered_tables)

        # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…å˜åŒ–ï¼Œå¦‚æœæ²¡æœ‰åˆ™è·³è¿‡æ›´æ–°
        current_hash = self._get_tables_hash(sorted_tables)
        if hasattr(self, '_last_tables_hash') and self._last_tables_hash == current_hash:
            return  # æ•°æ®æ²¡æœ‰å˜åŒ–ï¼Œè·³è¿‡æ›´æ–°

        # ä¿å­˜å½“å‰æ»šåŠ¨ä½ç½®
        current_scroll_y = table.scroll_y if hasattr(table, 'scroll_y') else 0

        # ä½¿ç”¨æ‰¹é‡æ›´æ–°å‡å°‘é—ªçƒ
        with self.app.batch_update():
            # æ¸…ç©ºè¡¨æ ¼å¹¶é‡æ–°å¡«å……
            table.clear()

            for i, t in enumerate(sorted_tables, 1):
                # çŠ¶æ€å›¾æ ‡
                if t.target_rows == -1 or t.source_rows == -1:
                    icon = "âŒ"
                elif t.is_consistent:
                    icon = "âœ…"
                else:
                    icon = "âš ï¸"

                # æ•°æ®å·®å¼‚æ–‡æœ¬å’Œæ ·å¼
                if t.target_rows == -1 or t.source_rows == -1:
                    diff_text = "[bold bright_red]ERROR[/]"
                else:
                    if t.data_diff < 0:
                        diff_text = f"[bold orange3]{t.data_diff:+,}[/]"
                    elif t.data_diff > 0:
                        diff_text = f"[bold bright_green]{t.data_diff:+,}[/]"
                    else:
                        diff_text = "[dim white]0[/]"



                # ç›®æ ‡æ›´æ–°æ—¶é—´æ ·å¼
                if t.target_updating:
                    target_time_display = "[yellow3]æ›´æ–°ä¸­[/]"
                else:
                    target_relative_time = self.get_relative_time(t.target_last_updated)
                    if "å¹´å‰" in target_relative_time or "ä¸ªæœˆå‰" in target_relative_time:
                        target_time_display = f"[bold orange1]{target_relative_time}[/]"
                    elif "å¤©å‰" in target_relative_time:
                        target_time_display = f"[bold yellow3]{target_relative_time}[/]"
                    elif "å°æ—¶å‰" in target_relative_time:
                        target_time_display = f"[bright_cyan]{target_relative_time}[/]"
                    else:
                        target_time_display = f"[dim bright_black]{target_relative_time}[/]"

                # æºæ›´æ–°æ—¶é—´æ ·å¼
                if t.source_updating:
                    source_time_display = "[yellow3]æ›´æ–°ä¸­[/]"
                else:
                    source_relative_time = self.get_relative_time(t.source_last_updated)
                    if "å¹´å‰" in source_relative_time or "ä¸ªæœˆå‰" in source_relative_time:
                        source_time_display = f"[bold orange1]{source_relative_time}[/]"
                    elif "å¤©å‰" in source_relative_time:
                        source_time_display = f"[bold yellow3]{source_relative_time}[/]"
                    elif "å°æ—¶å‰" in source_relative_time:
                        source_time_display = f"[bright_cyan]{source_relative_time}[/]"
                    else:
                        source_time_display = f"[dim bright_black]{source_relative_time}[/]"

                # è®°å½•æ•°æ˜¾ç¤ºå’Œæ ·å¼
                if t.target_rows == -1:
                    target_rows_display = "[bold bright_red]ERROR[/]"
                elif t.target_is_estimated:
                    target_rows_display = f"[italic bright_blue]~{t.target_rows:,}[/]"
                else:
                    target_rows_display = f"[bold bright_cyan]{t.target_rows:,}[/]"

                if t.source_rows == -1:
                    source_rows_display = "[bold bright_red]ERROR[/]"
                elif t.source_is_estimated:
                    source_rows_display = f"[italic green3]~{t.source_rows:,}[/]"
                else:
                    source_rows_display = f"[bold bright_green]{t.source_rows:,}[/]"

                # Schemaåç§°å’Œè¡¨åæ ·å¼
                schema_display = f"[bold medium_purple3]{t.schema_name[:12] + '...' if len(t.schema_name) > 15 else t.schema_name}[/]"
                table_display = f"[bold dodger_blue2]{t.target_table_name[:35] + '...' if len(t.target_table_name) > 38 else t.target_table_name}[/]"

                # æºè¡¨æ•°é‡æ ·å¼
                source_count = len(t.source_tables)
                if source_count >= 5:
                    source_count_display = f"[bold orange1]{source_count}[/]"
                elif source_count >= 3:
                    source_count_display = f"[bold yellow3]{source_count}[/]"
                elif source_count >= 2:
                    source_count_display = f"[bright_cyan]{source_count}[/]"
                else:
                    source_count_display = f"[dim bright_white]{source_count}[/]"

                # æ·»åŠ è¡Œåˆ°è¡¨æ ¼
                table.add_row(
                    str(i),
                    schema_display,
                    table_display,
                    icon,
                    target_rows_display,
                    source_rows_display,
                    diff_text,
                    target_time_display,
                    source_time_display,
                    source_count_display
                )

        # æ¢å¤æ»šåŠ¨ä½ç½®
        if current_scroll_y > 0 and hasattr(table, 'scroll_y'):
            try:
                max_scroll = table.max_scroll_y if hasattr(table, 'max_scroll_y') else current_scroll_y
                table.scroll_y = min(current_scroll_y, max_scroll)
            except Exception:
                pass  # å¦‚æœæ¢å¤å¤±è´¥ï¼Œä¿æŒé»˜è®¤ä½ç½®

        # ä¿å­˜å½“å‰å“ˆå¸Œå€¼
        self._last_tables_hash = current_hash

    def _get_tables_hash(self, tables: List[TableInfo]) -> str:
        """è·å–è¡¨æ ¼æ•°æ®çš„å“ˆå¸Œå€¼ç”¨äºå˜åŒ–æ£€æµ‹"""
        import hashlib
        data_str = ""
        for t in tables:
            data_str += f"{t.schema_name}:{t.target_table_name}:{t.target_rows}:{t.source_rows}:{t.data_diff}:{len(t.source_tables)}:"
        return hashlib.md5(data_str.encode()).hexdigest()





    def _rebuild_data_table(self, sorted_tables: List[TableInfo]):
        """é‡å»ºæ•°æ®è¡¨æ ¼ï¼ˆä»…åœ¨å¿…è¦æ—¶è°ƒç”¨ï¼‰"""
        table = self.query_one("#tables", DataTable)

        # ä¿å­˜å½“å‰æ»šåŠ¨ä½ç½®
        current_scroll_y = table.scroll_y if hasattr(table, 'scroll_y') else 0

        # ä½¿ç”¨æ‰¹é‡æ›´æ–°å‡å°‘é—ªçƒ
        with self.app.batch_update():
            # æ¸…ç©ºè¡¨æ ¼å¹¶é‡æ–°å¡«å……
            table.clear()

            for i, t in enumerate(sorted_tables, 1):
                # çŠ¶æ€å›¾æ ‡
                if t.target_rows == -1 or t.source_rows == -1:
                    icon = "âŒ"
                elif t.is_consistent:
                    icon = "âœ…"
                else:
                    icon = "âš ï¸"

                # æ•°æ®å·®å¼‚æ–‡æœ¬å’Œæ ·å¼
                if t.target_rows == -1 or t.source_rows == -1:
                    diff_text = "[bold bright_red]ERROR[/]"
                else:
                    if t.data_diff < 0:
                        diff_text = f"[bold orange3]{t.data_diff:+,}[/]"
                    elif t.data_diff > 0:
                        diff_text = f"[bold bright_green]{t.data_diff:+,}[/]"
                    else:
                        diff_text = "[dim white]0[/]"



                # ç›®æ ‡æ›´æ–°æ—¶é—´æ ·å¼
                if t.target_updating:
                    target_time_display = "[yellow3]æ›´æ–°ä¸­[/]"
                else:
                    target_relative_time = self.get_relative_time(t.target_last_updated)
                    if "å¹´å‰" in target_relative_time or "ä¸ªæœˆå‰" in target_relative_time:
                        target_time_display = f"[bold orange1]{target_relative_time}[/]"
                    elif "å¤©å‰" in target_relative_time:
                        target_time_display = f"[bold yellow3]{target_relative_time}[/]"
                    elif "å°æ—¶å‰" in target_relative_time:
                        target_time_display = f"[bright_cyan]{target_relative_time}[/]"
                    else:
                        target_time_display = f"[dim bright_black]{target_relative_time}[/]"

                # æºæ›´æ–°æ—¶é—´æ ·å¼
                if t.source_updating:
                    source_time_display = "[yellow3]æ›´æ–°ä¸­[/]"
                else:
                    source_relative_time = self.get_relative_time(t.source_last_updated)
                    if "å¹´å‰" in source_relative_time or "ä¸ªæœˆå‰" in source_relative_time:
                        source_time_display = f"[bold orange1]{source_relative_time}[/]"
                    elif "å¤©å‰" in source_relative_time:
                        source_time_display = f"[bold yellow3]{source_relative_time}[/]"
                    elif "å°æ—¶å‰" in source_relative_time:
                        source_time_display = f"[bright_cyan]{source_relative_time}[/]"
                    else:
                        source_time_display = f"[dim bright_black]{source_relative_time}[/]"

                # è®°å½•æ•°æ˜¾ç¤ºå’Œæ ·å¼
                if t.target_rows == -1:
                    target_rows_display = "[bold bright_red]ERROR[/]"
                elif t.target_is_estimated:
                    target_rows_display = f"[italic bright_blue]~{t.target_rows:,}[/]"
                else:
                    target_rows_display = f"[bold bright_cyan]{t.target_rows:,}[/]"

                if t.source_rows == -1:
                    source_rows_display = "[bold bright_red]ERROR[/]"
                elif t.source_is_estimated:
                    source_rows_display = f"[italic green3]~{t.source_rows:,}[/]"
                else:
                    source_rows_display = f"[bold bright_green]{t.source_rows:,}[/]"

                # Schemaåç§°å’Œè¡¨åæ ·å¼
                schema_display = f"[bold medium_purple3]{t.schema_name[:12] + '...' if len(t.schema_name) > 15 else t.schema_name}[/]"
                table_display = f"[bold dodger_blue2]{t.target_table_name[:35] + '...' if len(t.target_table_name) > 38 else t.target_table_name}[/]"

                # æºè¡¨æ•°é‡æ ·å¼
                source_count = len(t.source_tables)
                if source_count >= 5:
                    source_count_display = f"[bold orange1]{source_count}[/]"
                elif source_count >= 3:
                    source_count_display = f"[bold yellow3]{source_count}[/]"
                elif source_count >= 2:
                    source_count_display = f"[bright_cyan]{source_count}[/]"
                else:
                    source_count_display = f"[dim bright_white]{source_count}[/]"

                # æ·»åŠ è¡Œåˆ°è¡¨æ ¼
                table.add_row(
                    str(i),
                    schema_display,
                    table_display,
                    icon,
                    target_rows_display,
                    source_rows_display,
                    diff_text,
                    target_time_display,
                    source_time_display,
                    source_count_display
                )

        # æ¢å¤æ»šåŠ¨ä½ç½®
        if current_scroll_y > 0 and hasattr(table, 'scroll_y'):
            try:
                max_scroll = table.max_scroll_y if hasattr(table, 'max_scroll_y') else current_scroll_y
                table.scroll_y = min(current_scroll_y, max_scroll)
            except Exception:
                pass  # å¦‚æœæ¢å¤å¤±è´¥ï¼Œä¿æŒé»˜è®¤ä½ç½®

    async def refresh_data(self):
        """å®šæ—¶åˆ·æ–°æ•°æ®"""
        if self.stop_event.is_set() or self.is_paused:
            return

        # é‡æ–°æ„å»ºtarget_tablesç»“æ„ç”¨äºæ›´æ–°
        # æ•°æ®ä¸ä¸€è‡´çš„è¡¨å§‹ç»ˆæ›´æ–°ï¼Œæ•°æ®ä¸€è‡´çš„è¡¨æ ¹æ®pause_auto_refreshå†³å®š
        target_tables = {}
        skipped_count = 0
        for table_info in self.tables:
            # å¦‚æœæ•°æ®ä¸ä¸€è‡´ï¼Œå§‹ç»ˆæ›´æ–°ï¼ˆå¿½ç•¥pause_auto_refreshï¼‰
            # å¦‚æœæ•°æ®ä¸€è‡´ä¸”æš‚åœè‡ªåŠ¨åˆ·æ–°ï¼Œåˆ™è·³è¿‡
            if table_info.is_consistent and table_info.pause_auto_refresh:
                skipped_count += 1
                continue
            schema_name = table_info.schema_name
            if schema_name not in target_tables:
                target_tables[schema_name] = {}
            target_tables[schema_name][table_info.target_table_name] = table_info

        # å¦‚æœæ²¡æœ‰éœ€è¦æ›´æ–°çš„è¡¨ï¼Œç›´æ¥è¿”å›
        if not target_tables:
            self.log(f"æ‰€æœ‰è¡¨éƒ½å·²æš‚åœè‡ªåŠ¨åˆ·æ–°æˆ–æ•°æ®ä¸€è‡´ï¼Œè·³è¿‡æ›´æ–° (å…±è·³è¿‡ {skipped_count} ä¸ªè¡¨)")
            return
        else:
            self.log(f"è‡ªåŠ¨åˆ·æ–° {len(target_tables)} ä¸ªschemaçš„è¡¨ï¼Œè·³è¿‡ {skipped_count} ä¸ªå·²æš‚åœçš„è¡¨")

        # æ›´æ–°ç›®æ ‡MySQLè®°å½•æ•°
        self.target_iteration += 1
        await self.update_target_counts_async(target_tables)

        # æŒ‰é—´éš”æ›´æ–°æºMySQLè®°å½•æ•°
        if self.target_iteration % self.source_update_interval == 0:
            self.source_iteration += 1
            await self.update_source_counts_async(target_tables, use_information_schema=False)

        # æ›´æ–°è¿›åº¦è·Ÿè¸ªæ•°æ®
        self.update_progress_data(self.tables)

        # æ›´æ–°æ˜¾ç¤º
        self.update_display()

    def action_quit(self) -> None:
        """é€€å‡ºåº”ç”¨"""
        self.stop_event.set()
        if self.refresh_timer:
            self.refresh_timer.stop()
        self.exit()

    def action_refresh(self) -> None:
        """æ‰‹åŠ¨åˆ·æ–°"""
        # é‡ç½®æ‰€æœ‰è¡¨çš„æš‚åœçŠ¶æ€
        for table_info in self.tables:
            table_info.pause_auto_refresh = False
        self.log("æ‰‹åŠ¨åˆ·æ–°ï¼Œé‡ç½®æ‰€æœ‰è¡¨çš„æš‚åœçŠ¶æ€")

        self.call_later(self.refresh_data)

    def action_toggle_pause(self) -> None:
        """æš‚åœ/ç»§ç»­ç›‘æ§"""
        self.is_paused = not self.is_paused
        self.update_display()

    def action_sort_toggle(self) -> None:
        """åˆ‡æ¢æ’åºæ–¹å¼"""
        sort_options = ["schema_table", "data_diff", "target_rows", "source_rows"]
        current_index = sort_options.index(self.sort_by)
        self.sort_by = sort_options[(current_index + 1) % len(sort_options)]
        self.update_display()

    def action_filter_toggle(self) -> None:
        """åˆ‡æ¢è¿‡æ»¤æ–¹å¼"""
        filter_options = ["all", "inconsistent", "consistent", "error"]
        current_index = filter_options.index(self.filter_mode)
        self.filter_mode = filter_options[(current_index + 1) % len(filter_options)]
        self.update_display()

    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨"""
        self.stop_event.set()
        self.exit()

    def get_relative_time(self, target_time: datetime) -> str:
        """è·å–ç›¸å¯¹æ—¶é—´æ˜¾ç¤º"""
        now = datetime.now()
        diff = now - target_time

        # è®¡ç®—æ€»ç§’æ•°
        total_seconds = int(diff.total_seconds())

        if total_seconds < 0:
            return "åˆšåˆš"
        elif total_seconds < 60:
            return f"{total_seconds}ç§’å‰"
        elif total_seconds < 3600:  # å°äº1å°æ—¶
            minutes = total_seconds // 60
            return f"{minutes}åˆ†é’Ÿå‰"
        elif total_seconds < 86400:  # å°äº1å¤©
            hours = total_seconds // 3600
            return f"{hours}å°æ—¶å‰"
        elif total_seconds < 2592000:  # å°äº30å¤©
            days = total_seconds // 86400
            return f"{days}å¤©å‰"
        elif total_seconds < 31536000:  # å°äº1å¹´
            months = total_seconds // 2592000
            return f"{months}ä¸ªæœˆå‰"
        else:
            years = total_seconds // 31536000
            return f"{years}å¹´å‰"

    def update_progress_data(self, tables: List[TableInfo]):
        """æ›´æ–°è¿›åº¦æ•°æ®ï¼Œè®¡ç®—æ€»æ•°"""
        current_time = datetime.now()

        # è¿‡æ»¤æ‰é”™è¯¯çŠ¶æ€çš„è¡¨è¿›è¡Œç»Ÿè®¡
        valid_tables = [t for t in tables if t.target_rows != -1 and t.source_rows != -1]

        total_target_rows = sum(t.target_rows for t in valid_tables)
        total_source_rows = sum(t.source_rows for t in valid_tables)

        # æ·»åŠ åˆ°å†å²æ•°æ®
        self.history_data.append((current_time, total_target_rows, total_source_rows, 0))

        # ä¿æŒå†å²æ•°æ®åœ¨æŒ‡å®šèŒƒå›´å†…
        if len(self.history_data) > self.max_history_points:
            self.history_data.pop(0)





    async def load_config(self) -> bool:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_path = Path(self.config_file)
        if not config_path.exists():
            return False

        try:
            config = ConfigParser()
            config.read(config_path, encoding='utf-8')

            # æºæ•°æ®åº“ MySQL é…ç½®
            source_section = config['source']
            self.source_config = MySQLConfig(
                host=source_section['host'],
                port=int(source_section['port']),
                database="",
                username=source_section['username'],
                password=source_section['password']
            )

            # ç›®æ ‡æ•°æ®åº“ MySQL é…ç½®
            target_section = config['target']
            self.target_config = MySQLConfig(
                host=target_section['host'],
                port=int(target_section['port']),
                database="",
                username=target_section['username'],
                password=target_section['password']
            )

            # ç›‘æ§é…ç½®
            monitor_section = config['monitor']
            if self.override_databases:
                databases_list = self.override_databases
            else:
                databases_list = [db.strip() for db in monitor_section['databases'].split(',')]

            self.monitor_config = {
                'databases': databases_list,
                'refresh_interval': int(monitor_section.get('refresh_interval', 2)),
                'source_update_interval': int(monitor_section.get('source_update_interval', 5)),
                'ignored_table_prefixes': monitor_section.get('ignored_table_prefixes', '').split(',')
            }

            self.source_update_interval = self.monitor_config['source_update_interval']
            return True

        except Exception as e:
            return False

    async def connect_source(self, database: str):
        """è¿æ¥æºMySQL"""
        try:
            conn = await aiomysql.connect(
                host=self.source_config.host,
                port=self.source_config.port,
                db=database,
                user=self.source_config.username,
                password=self.source_config.password,
                connect_timeout=5,
                charset='utf8mb4'
            )
            return conn
        except Exception as e:
            return None

    async def connect_target(self, database: str):
        """è¿æ¥ç›®æ ‡MySQL"""
        try:
            conn = await aiomysql.connect(
                host=self.target_config.host,
                port=self.target_config.port,
                db=database,
                user=self.target_config.username,
                password=self.target_config.password,
                connect_timeout=5,
                charset='utf8mb4'
            )
            return conn
        except Exception as e:
            return None

    async def initialize_tables_from_target(self):
        """ä»ç›®æ ‡MySQLåˆå§‹åŒ–è¡¨ç»“æ„ï¼Œä»¥ç›®æ ‡æ•°æ®åº“çš„è¡¨ä¸ºå‡†"""
        schema_tables = {}

        for schema_name in self.monitor_config['databases']:
            schema_name = schema_name.strip()
            if not schema_name:
                continue

            # å…ˆè·å–ç›®æ ‡æ•°æ®åº“çš„è¡¨ç»“æ„
            target_conn = await self.connect_target(schema_name)
            if not target_conn:
                continue

            try:
                async with target_conn.cursor() as cursor:
                    await cursor.execute("""
                                         SELECT TABLE_NAME
                                         FROM INFORMATION_SCHEMA.TABLES
                                         WHERE TABLE_SCHEMA = %s
                                           AND TABLE_TYPE = 'BASE TABLE'
                                         """, (schema_name,))

                    target_table_names = []
                    rows = await cursor.fetchall()
                    for row in rows:
                        table_name = row[0]
                        if not any(table_name.startswith(prefix.strip())
                                   for prefix in self.monitor_config['ignored_table_prefixes'] if prefix.strip()):
                            target_table_names.append(table_name)

                # è·å–æºæ•°æ®åº“çš„è¡¨ç»“æ„ç”¨äºåŒ¹é…
                source_conn = await self.connect_source(schema_name)
                source_table_names = []
                if source_conn:
                    try:
                        async with source_conn.cursor() as cursor:
                            await cursor.execute("""
                                                 SELECT TABLE_NAME
                                                 FROM INFORMATION_SCHEMA.TABLES
                                                 WHERE TABLE_SCHEMA = %s
                                                   AND TABLE_TYPE = 'BASE TABLE'
                                                 """, (schema_name,))
                            rows = await cursor.fetchall()
                            for row in rows:
                                table_name = row[0]
                                if not any(table_name.startswith(prefix.strip())
                                           for prefix in self.monitor_config['ignored_table_prefixes'] if prefix.strip()):
                                    source_table_names.append(table_name)
                    finally:
                        source_conn.close()

                # åˆ›å»ºç›®æ ‡è¡¨ä¿¡æ¯
                target_tables = {}
                for target_table_name in target_table_names:
                    current_time = datetime.now()
                    target_tables[target_table_name] = TableInfo(
                        schema_name=schema_name,
                        target_table_name=target_table_name,
                        target_rows=0,
                        source_rows=0,
                        source_last_updated=current_time - timedelta(days=365),
                        target_last_updated=current_time - timedelta(days=365),
                        last_updated=current_time
                    )

                    # åå‘æ˜ å°„é€»è¾‘ï¼šæ”¶é›†æ‰€æœ‰æ˜ å°„åˆ°è¯¥ç›®æ ‡è¡¨çš„æºè¡¨
                    # æ¸…ç©ºæºè¡¨åˆ—è¡¨ï¼Œå‡†å¤‡é‡æ–°æ”¶é›†
                    target_tables[target_table_name].source_tables = []

                    # 1. ç›´æ¥åŒ¹é…ï¼šå¦‚æœç›®æ ‡è¡¨ååœ¨æºè¡¨ä¸­å­˜åœ¨ï¼Œæ·»åŠ ä¸ºæºè¡¨
                    if target_table_name in source_table_names:
                        target_tables[target_table_name].source_tables.append(target_table_name)

                    # 2. è½¬æ¢è§„åˆ™åŒ¹é…ï¼šæ”¶é›†æ‰€æœ‰æ˜ å°„åˆ°è¯¥ç›®æ ‡è¡¨çš„æºè¡¨
                    for source_table in source_table_names:
                        mapped_target = self.sync_props.get_target_table_name(source_table)
                        if mapped_target == target_table_name:
                            # é¿å…é‡å¤æ·»åŠ 
                            if source_table not in target_tables[target_table_name].source_tables:
                                target_tables[target_table_name].source_tables.append(source_table)

                    # 3. å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æºè¡¨ï¼Œä½¿ç”¨ç›®æ ‡è¡¨åä½œä¸ºæºè¡¨åï¼ˆé»˜è®¤æƒ…å†µï¼‰
                    if not target_tables[target_table_name].source_tables:
                        target_tables[target_table_name].source_tables.append(target_table_name)

                    # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºæ˜ å°„å…³ç³»
                    if len(target_tables[target_table_name].source_tables) > 1:
                        self.log(f"è¡¨æ˜ å°„: {target_table_name} <- {target_tables[target_table_name].source_tables}")

                if target_tables:
                    schema_tables[schema_name] = target_tables

            finally:
                target_conn.close()

        return schema_tables

    async def get_source_rows_from_information_schema(self, conn, target_tables: Dict[str, Dict[str, TableInfo]]):
        """ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ä½¿ç”¨information_schemaå¿«é€Ÿè·å–æºMySQLè¡¨è¡Œæ•°ä¼°è®¡å€¼"""
        current_time = datetime.now()

        try:
            for schema_name, tables_dict in target_tables.items():
                try:
                    # æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆ
                    if conn is None or not hasattr(conn, 'closed') or conn.closed:
                        return

                    # æ”¶é›†æ‰€æœ‰éœ€è¦æŸ¥è¯¢çš„æºè¡¨
                    all_source_tables = set()
                    for table_info in tables_dict.values():
                        all_source_tables.update(table_info.source_tables)

                    if not all_source_tables:
                        continue

                    # ä¸€æ¬¡æ€§è·å–æ‰€æœ‰æºè¡¨çš„ç»Ÿè®¡ä¿¡æ¯
                    async with conn.cursor() as cursor:
                        placeholders = ','.join(['%s'] * len(all_source_tables))
                        await cursor.execute(f"""
                            SELECT table_name, table_rows
                            FROM information_schema.tables
                            WHERE table_schema = %s
                            AND table_name IN ({placeholders})
                        """, (schema_name, *all_source_tables))

                        # å»ºç«‹è¡¨ååˆ°ä¼°è®¡è¡Œæ•°çš„æ˜ å°„
                        source_stats_map = {}
                        rows = await cursor.fetchall()
                        for row in rows:
                            table_name, table_rows = row[0], row[1]
                            source_stats_map[table_name] = max(0, table_rows or 0)

                    # æ›´æ–°æ¯ä¸ªç›®æ ‡è¡¨çš„æºè¡Œæ•°ï¼ˆä¼°ç®—å€¼ï¼‰
                    for target_table_name, table_info in tables_dict.items():
                        total_source_rows = 0
                        for source_table_name in table_info.source_tables:
                            if source_table_name in source_stats_map:
                                total_source_rows += source_stats_map[source_table_name]

                        if not table_info.is_first_query:
                            table_info.previous_source_rows = table_info.source_rows
                        else:
                            table_info.previous_source_rows = total_source_rows
                            table_info.is_first_query = False

                        table_info.source_rows = total_source_rows
                        table_info.source_last_updated = current_time
                        table_info.source_is_estimated = True  # é¦–æ¬¡ä½¿ç”¨ä¼°ç®—å€¼
                        # é¦–æ¬¡ä¼°ç®—å€¼ä¸æš‚åœè‡ªåŠ¨åˆ·æ–°ï¼Œç­‰å¾…ç²¾ç¡®å€¼

                except Exception as e:
                    # å¦‚æœinformation_schemaæŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°é€è¡¨ç²¾ç¡®æŸ¥è¯¢
                    if conn is not None and hasattr(conn, 'closed') and not conn.closed:
                        await self.update_source_counts(conn, {schema_name: tables_dict}, use_information_schema=True)
        except Exception as e:
            print(f"get_source_rows_from_information_schema å¼‚å¸¸: {e}")

    async def get_target_rows_from_information_schema(self, conn, target_tables: Dict[str, Dict[str, TableInfo]]):
        """ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ä½¿ç”¨information_schemaå¿«é€Ÿè·å–ç›®æ ‡MySQLè¡¨è¡Œæ•°ä¼°è®¡å€¼"""
        current_time = datetime.now()
        self.target_updating = True

        try:
            for schema_name, tables_dict in target_tables.items():
                try:
                    # æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆ
                    if conn is None or not hasattr(conn, 'closed') or conn.closed:
                        return

                    # ä¸€æ¬¡æ€§è·å–è¯¥schemaä¸‹æ‰€æœ‰è¡¨çš„ç»Ÿè®¡ä¿¡æ¯
                    async with conn.cursor() as cursor:
                        await cursor.execute("""
                                             SELECT TABLE_NAME, TABLE_ROWS
                                             FROM INFORMATION_SCHEMA.TABLES
                                             WHERE TABLE_SCHEMA = %s
                                               AND TABLE_TYPE = 'BASE TABLE'
                                             """, (schema_name,))

                        # å»ºç«‹è¡¨ååˆ°ä¼°è®¡è¡Œæ•°çš„æ˜ å°„
                        target_stats_map = {}
                        rows = await cursor.fetchall()
                        for row in rows:
                            table_name, table_rows = row[0], row[1]
                            target_stats_map[table_name] = max(0, table_rows or 0)  # å¤„ç†NULLå€¼

                    # æ›´æ–°TableInfoä¸­çš„ç›®æ ‡è¡Œæ•°
                    for target_table_name, table_info in tables_dict.items():
                        if target_table_name in target_stats_map:
                            new_count = target_stats_map[target_table_name]
                        else:
                            # å¦‚æœç»Ÿè®¡ä¿¡æ¯ä¸­æ²¡æœ‰ï¼Œå¯èƒ½æ˜¯æ–°è¡¨æˆ–æ— æ•°æ®ï¼Œä½¿ç”¨ç²¾ç¡®æŸ¥è¯¢
                            try:
                                # å†æ¬¡æ£€æŸ¥è¿æ¥çŠ¶æ€
                                if conn is None or not hasattr(conn, 'closed') or conn.closed:
                                    continue
                                async with conn.cursor() as cursor:
                                    await cursor.execute(f"SELECT COUNT(*) FROM `{schema_name}`.`{target_table_name}`")
                                    result = await cursor.fetchone()
                                    new_count = result[0] if result else 0
                            except:
                                new_count = -1  # æŸ¥è¯¢å¤±è´¥æ ‡è®°ä¸º-1

                        if not table_info.is_first_query:
                            table_info.previous_target_rows = table_info.target_rows
                        else:
                            table_info.previous_target_rows = new_count
                            table_info.is_first_query = False

                        table_info.target_rows = new_count
                        table_info.target_last_updated = current_time
                        table_info.target_is_estimated = True  # é¦–æ¬¡ä½¿ç”¨ä¼°ç®—å€¼
                        table_info.target_updating = False  # é‡ç½®æ›´æ–°çŠ¶æ€

                except Exception as e:
                    # ä¼°ç®—è·å–å¤±è´¥å°±å¤±è´¥ï¼Œä¸å›é€€åˆ°ç²¾ç¡®æŸ¥è¯¢
                    pass  # ä¿æŒå½“å‰çŠ¶æ€ï¼Œè®©è¡¨æ ¼æ˜¾ç¤ºä¸ºé”™è¯¯çŠ¶æ€
        except Exception as e:
            # æ•è·æ–¹æ³•çº§åˆ«çš„å¼‚å¸¸ï¼Œé˜²æ­¢è¿æ¥å¯¹è±¡è¢«ç ´å
            print(f"get_target_rows_from_information_schema å¼‚å¸¸: {e}")
        finally:
            self.target_updating = False

    async def _update_single_schema_source(self, schema_name: str, tables_dict: Dict[str, TableInfo],
                                           use_information_schema: bool = False) -> bool:
        """æ›´æ–°å•ä¸ªschemaçš„æºMySQLè®°å½•æ•°ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼Œæ”¯æŒä¸­æ–­ï¼‰"""
        current_time = datetime.now()

        # æ£€æŸ¥æ˜¯å¦æ”¶åˆ°åœæ­¢ä¿¡å·
        if self.stop_event.is_set():
            return False

        try:
            source_conn = await self.connect_source(schema_name)
            if not source_conn:
                return False

            try:
                if use_information_schema:
                    # æ£€æŸ¥åœæ­¢æ ‡å¿—
                    if self.stop_event.is_set():
                        return False

                    # é¦–å…ˆæ ‡è®°æ‰€æœ‰è¡¨ä¸ºæ›´æ–°ä¸­çŠ¶æ€
                    async with self.source_update_lock:
                        for table_info in tables_dict.values():
                            if not table_info.source_updating:
                                table_info.source_updating = True
                                table_info.source_rows = 0  # é‡ç½®
                                self.log(f"æºè¡¨ {table_info.target_table_name} å¼€å§‹æ›´æ–°")

                    # ç«‹å³æ›´æ–°æ˜¾ç¤ºä»¥ç¡®ä¿èƒ½çœ‹åˆ°"æ›´æ–°ä¸­"çŠ¶æ€
                    self.call_from_thread(self.update_display)

                    # ä½¿ç”¨æ‰¹é‡æŸ¥è¯¢è·å–æ‰€æœ‰æºè¡¨çš„ä¼°è®¡è¡Œæ•°
                    if tables_dict:
                        # æ„å»ºæ‰€æœ‰éœ€è¦æŸ¥è¯¢çš„æºè¡¨
                        all_source_tables = []
                        table_source_map = {}  # è®°å½•æ¯ä¸ªç›®æ ‡è¡¨å¯¹åº”çš„æºè¡¨

                        for target_table_name, table_info in tables_dict.items():
                            table_source_map[target_table_name] = table_info.source_tables
                            all_source_tables.extend(table_info.source_tables)

                        # å»é‡
                        unique_source_tables = list(set(all_source_tables))

                        if unique_source_tables:
                            try:
                                async with source_conn.cursor() as cursor:
                                    # æ„å»ºINæŸ¥è¯¢æ‰¹é‡è·å–æ‰€æœ‰æºè¡¨çš„è¡Œæ•°
                                    placeholders = ','.join(['%s'] * len(unique_source_tables))
                                    await cursor.execute(f"""
                                        SELECT table_name, table_rows
                                        FROM information_schema.tables
                                        WHERE table_schema = %s
                                        AND table_name IN ({placeholders})
                                    """, (schema_name, *unique_source_tables))

                                    # å»ºç«‹è¡¨ååˆ°è¡Œæ•°çš„æ˜ å°„
                                    source_rows_map = {}
                                    rows = await cursor.fetchall()
                                    for row in rows:
                                        table_name, table_rows = row[0], row[1]
                                        source_rows_map[table_name] = max(0, table_rows or 0)

                                    # æ›´æ–°æ¯ä¸ªç›®æ ‡è¡¨çš„æºè¡Œæ•°
                                    for target_table_name, table_info in tables_dict.items():
                                        if self.stop_event.is_set():
                                            async with self.source_update_lock:
                                                table_info.source_updating = False
                                            return False

                                        total_source_rows = 0
                                        for source_table_name in table_source_map[target_table_name]:
                                            if source_table_name in source_rows_map:
                                                total_source_rows += source_rows_map[source_table_name]
                                            else:
                                                # è¡¨ä¸å­˜åœ¨æˆ–æŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•ç²¾ç¡®æŸ¥è¯¢
                                                try:
                                                    async with source_conn.cursor() as cursor2:
                                                        await cursor2.execute(f"SELECT COUNT(*) FROM `{schema_name}`.`{source_table_name}`")
                                                        result = await cursor2.fetchone()
                                                        if result:
                                                            total_source_rows += result[0]
                                                except:
                                                    continue

                                        async with self.source_update_lock:
                                            table_info.source_rows = total_source_rows
                                            table_info.source_last_updated = current_time
                                            table_info.source_updating = False
                                            table_info.source_is_estimated = True  # ä»…å½“ä½¿ç”¨information_schema.tables.table_rowsæ—¶ä¸ºä¼°ç®—å€¼

                            except Exception as e:
                                # æ‰¹é‡æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°é€ä¸ªæŸ¥è¯¢
                                for target_table_name, table_info in tables_dict.items():
                                    if self.stop_event.is_set():
                                        async with self.source_update_lock:
                                            table_info.source_updating = False
                                        return False

                                    total_source_rows = 0
                                    for source_table_name in table_info.source_tables:
                                        try:
                                            async with source_conn.cursor() as cursor:
                                                await cursor.execute("""
                                                    SELECT table_rows
                                                    FROM information_schema.tables
                                                    WHERE table_schema = %s
                                                    AND table_name = %s
                                                """, (schema_name, source_table_name))
                                                result = await cursor.fetchone()
                                                if result and result[0]:
                                                    total_source_rows += result[0]
                                        except:
                                            continue

                                    async with self.source_update_lock:
                                        table_info.source_rows = total_source_rows
                                        table_info.source_last_updated = current_time
                                        table_info.source_updating = False
                                        table_info.source_is_estimated = True  # ä»…å½“ä½¿ç”¨information_schema.tables.table_rowsæ—¶ä¸ºä¼°ç®—å€¼
                                        # ä¼°ç®—å€¼ä¸æš‚åœè‡ªåŠ¨åˆ·æ–°ï¼Œç­‰å¾…ç²¾ç¡®å€¼
                else:
                    # å¸¸è§„æ›´æ–°ä½¿ç”¨ç²¾ç¡®çš„COUNTæŸ¥è¯¢
                    # é¦–å…ˆæ ‡è®°æ‰€æœ‰è¡¨ä¸ºæ›´æ–°ä¸­çŠ¶æ€
                    async with self.source_update_lock:
                        for table_info in tables_dict.values():
                            if not table_info.source_updating:
                                table_info.source_updating = True

                    # ç„¶åé€ä¸ªå¤„ç†è¡¨
                    for table_info in tables_dict.values():
                        # æ£€æŸ¥åœæ­¢æ ‡å¿—
                        if self.stop_event.is_set():
                            # æ¢å¤æ‰€æœ‰è¡¨çš„çŠ¶æ€
                            async with self.source_update_lock:
                                for ti in tables_dict.values():
                                    ti.source_updating = False
                            return False

                        # æ›´æ–°æºè®°å½•æ•°ï¼ˆä½¿ç”¨æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–ï¼‰
                        temp_source_rows = 0

                        if table_info.source_tables:
                            # æ„å»ºæ‰¹é‡æŸ¥è¯¢SQL
                            source_tables = [f"'{table}'" for table in table_info.source_tables]
                            tables_str = ",".join(source_tables)

                            try:
                                async with source_conn.cursor() as cursor:
                                    # ä½¿ç”¨UNION ALLæ‰¹é‡æŸ¥è¯¢æ‰€æœ‰æºè¡¨
                                    if len(table_info.source_tables) == 1:
                                        # å•ä¸ªæºè¡¨ç›´æ¥æŸ¥è¯¢
                                        await cursor.execute(
                                            f"SELECT COUNT(*) FROM `{schema_name}`.`{table_info.source_tables[0]}`"
                                        )
                                        result = await cursor.fetchone()
                                        if result:
                                            temp_source_rows = result[0]
                                    else:
                                        # å¤šä¸ªæºè¡¨ä½¿ç”¨æ‰¹é‡æŸ¥è¯¢
                                        union_queries = []
                                        for source_table in table_info.source_tables:
                                            union_queries.append(
                                                f"SELECT COUNT(*) as cnt FROM `{schema_name}`.`{source_table}`"
                                            )

                                        batch_sql = " UNION ALL ".join(union_queries)
                                        await cursor.execute(batch_sql)

                                        # æ±‡æ€»æ‰€æœ‰ç»“æœ
                                        results = await cursor.fetchall()
                                        temp_source_rows = sum(row[0] for row in results)

                            except Exception as e:
                                # æ‰¹é‡æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°é€ä¸ªæŸ¥è¯¢
                                self.log(f"æ‰¹é‡æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°é€ä¸ªæŸ¥è¯¢: {e}")
                                temp_source_rows = 0
                                for source_table_name in table_info.source_tables:
                                    if self.stop_event.is_set():
                                        async with self.source_update_lock:
                                            for ti in tables_dict.values():
                                                ti.source_updating = False
                                        return False

                                    try:
                                        async with source_conn.cursor() as cursor:
                                            await cursor.execute(f"SELECT COUNT(*) FROM `{schema_name}`.`{source_table_name}`")
                                            result = await cursor.fetchone()
                                            if result:
                                                temp_source_rows += result[0]
                                    except Exception as e2:
                                        continue

                        # æŸ¥è¯¢å®Œæˆåæ›´æ–°ç»“æœ
                        async with self.source_update_lock:
                            table_info.source_rows = temp_source_rows
                            table_info.source_last_updated = current_time
                            table_info.source_updating = False
                            table_info.source_is_estimated = False  # æ ‡è®°ä¸ºç²¾ç¡®å€¼
                            self.log(f"æºè¡¨ {table_info.target_table_name} æ›´æ–°å®Œæˆï¼Œæºè¡¨æ•°é‡: {len(table_info.source_tables)}, æ€»è®°å½•æ•°: {temp_source_rows}")

                            # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸€è‡´ï¼Œå¦‚æœä¸€è‡´åˆ™æš‚åœè‡ªåŠ¨åˆ·æ–°
                            if table_info.is_consistent:
                                table_info.pause_auto_refresh = True
                                self.log(f"è¡¨ {table_info.target_table_name} æ•°æ®ä¸€è‡´ï¼Œæš‚åœè‡ªåŠ¨åˆ·æ–°")

                return True
            finally:
                source_conn.close()

        except Exception as e:
            # å‡ºç°å¼‚å¸¸æ—¶ï¼Œæ ‡è®°æ‰€æœ‰è¡¨çš„source_updatingä¸ºFalse
            async with self.source_update_lock:
                for table_info in tables_dict.values():
                    if table_info.source_updating:
                        table_info.source_updating = False
            return False

    async def update_source_counts(self, target_tables: Dict[str, Dict[str, TableInfo]],
                                   use_information_schema: bool = False):
        """æ›´æ–°æºMySQLè®°å½•æ•°ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œç”¨äºå…¼å®¹æ€§ï¼‰"""
        for schema_name, tables_dict in target_tables.items():
            await self._update_single_schema_source(schema_name, tables_dict, use_information_schema)

    async def update_source_counts_async(self, target_tables: Dict[str, Dict[str, TableInfo]],
                                         use_information_schema: bool = False):
        """å¼‚æ­¥æ›´æ–°æºMySQLè®°å½•æ•°ï¼ˆä¸é˜»å¡ä¸»çº¿ç¨‹ï¼‰"""
        # æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
        self.source_update_tasks = [f for f in self.source_update_tasks if not f.done()]

        # ä¸ºæ¯ä¸ªschemaæäº¤å¼‚æ­¥æ›´æ–°ä»»åŠ¡
        for schema_name, tables_dict in target_tables.items():
            # æ£€æŸ¥è¯¥schemaæ˜¯å¦å·²ç»æœ‰æ­£åœ¨è¿›è¡Œçš„æ›´æ–°ä»»åŠ¡
            schema_updating = False
            async with self.source_update_lock:
                for table_info in tables_dict.values():
                    if table_info.source_updating:
                        schema_updating = True
                        break

            if not schema_updating:
                future = asyncio.create_task(
                    self._update_single_schema_source(schema_name, tables_dict, use_information_schema))
                self.source_update_tasks.append(future)

    async def _update_single_schema_target(self, schema_name: str, tables_dict: Dict[str, TableInfo],
                                           use_information_schema: bool = False) -> bool:
        """æ›´æ–°å•ä¸ªschemaçš„ç›®æ ‡MySQLè®°å½•æ•°ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼Œæ”¯æŒä¸­æ–­ï¼‰"""
        current_time = datetime.now()

        # æ£€æŸ¥æ˜¯å¦æ”¶åˆ°åœæ­¢ä¿¡å·
        if self.stop_event.is_set():
            return False

        try:
            target_conn = await self.connect_target(schema_name)
            if not target_conn:
                return False

            try:
                if use_information_schema:
                    # æ£€æŸ¥åœæ­¢æ ‡å¿—
                    if self.stop_event.is_set():
                        return False

                    # é¦–å…ˆæ ‡è®°æ‰€æœ‰è¡¨ä¸ºæ›´æ–°ä¸­çŠ¶æ€
                    async with self.target_update_lock:
                        for table_info in tables_dict.values():
                            if not table_info.target_updating:
                                table_info.target_updating = True
                                table_info.target_rows = 0  # é‡ç½®
                                self.log(f"ç›®æ ‡è¡¨ {table_info.target_table_name} å¼€å§‹æ›´æ–°")

                    # ç«‹å³æ›´æ–°æ˜¾ç¤ºä»¥ç¡®ä¿èƒ½çœ‹åˆ°"æ›´æ–°ä¸­"çŠ¶æ€
                    self.call_from_thread(self.update_display)

                    # ä½¿ç”¨æ‰¹é‡æŸ¥è¯¢è·å–æ‰€æœ‰ç›®æ ‡è¡¨çš„ä¼°è®¡è¡Œæ•°
                    if tables_dict:
                        try:
                            async with target_conn.cursor() as cursor:
                                # ä¸€æ¬¡æ€§è·å–è¯¥schemaä¸‹æ‰€æœ‰è¡¨çš„ç»Ÿè®¡ä¿¡æ¯
                                await cursor.execute("""
                                                     SELECT TABLE_NAME, TABLE_ROWS
                                                     FROM INFORMATION_SCHEMA.TABLES
                                                     WHERE TABLE_SCHEMA = %s
                                                       AND TABLE_TYPE = 'BASE TABLE'
                                                     """, (schema_name,))

                                # å»ºç«‹è¡¨ååˆ°ä¼°è®¡è¡Œæ•°çš„æ˜ å°„
                                target_stats_map = {}
                                rows = await cursor.fetchall()
                                for row in rows:
                                    table_name, table_rows = row[0], row[1]
                                    target_stats_map[table_name] = max(0, table_rows or 0)

                                # æ›´æ–°æ¯ä¸ªç›®æ ‡è¡¨çš„è¡Œæ•°
                                for target_table_name, table_info in tables_dict.items():
                                    if self.stop_event.is_set():
                                        async with self.target_update_lock:
                                            table_info.target_updating = False
                                        return False

                                    if target_table_name in target_stats_map:
                                        new_count = target_stats_map[target_table_name]
                                    else:
                                        # å¦‚æœç»Ÿè®¡ä¿¡æ¯ä¸­æ²¡æœ‰ï¼Œå¯èƒ½æ˜¯æ–°è¡¨æˆ–æ— æ•°æ®ï¼Œä½¿ç”¨ç²¾ç¡®æŸ¥è¯¢
                                        try:
                                            async with target_conn.cursor() as cursor2:
                                                await cursor2.execute(f"SELECT COUNT(*) FROM `{schema_name}`.`{target_table_name}`")
                                                result = await cursor2.fetchone()
                                                new_count = result[0] if result else 0
                                        except:
                                            new_count = -1

                                    async with self.target_update_lock:
                                        if not table_info.is_first_query:
                                            table_info.previous_target_rows = table_info.target_rows
                                        else:
                                            table_info.previous_target_rows = new_count
                                            table_info.is_first_query = False

                                        table_info.target_rows = new_count
                                        table_info.target_last_updated = current_time
                                        table_info.target_updating = False
                                        table_info.target_is_estimated = True  # æ ‡è®°ä¸ºä¼°ç®—å€¼
                                        self.log(f"ç›®æ ‡è¡¨ {table_info.target_table_name} æ›´æ–°å®Œæˆï¼Œè¡Œæ•°: {new_count}")

                        except Exception as e:
                            # ä¼°ç®—è·å–å¤±è´¥å°±å¤±è´¥ï¼Œä¸å›é€€
                            for target_table_name, table_info in tables_dict.items():
                                if self.stop_event.is_set():
                                    async with self.target_update_lock:
                                        table_info.target_updating = False
                                    return False

                                # ä¼°ç®—å¤±è´¥ï¼Œè®¾ç½®ä¸ºé”™è¯¯çŠ¶æ€
                                async with self.target_update_lock:
                                    if not table_info.is_first_query:
                                        table_info.previous_target_rows = table_info.target_rows
                                    else:
                                        table_info.previous_target_rows = -1
                                        table_info.is_first_query = False

                                    table_info.target_rows = -1  # æ ‡è®°ä¸ºé”™è¯¯çŠ¶æ€
                                    table_info.target_last_updated = current_time
                                    table_info.target_updating = False
                                    table_info.target_is_estimated = True  # ä»ç„¶æ˜¯ä¼°ç®—å€¼ï¼Œä½†å¤±è´¥äº†
                else:
                    # å¸¸è§„æ›´æ–°ä½¿ç”¨ç²¾ç¡®çš„COUNTæŸ¥è¯¢
                    # é¦–å…ˆæ ‡è®°æ‰€æœ‰è¡¨ä¸ºæ›´æ–°ä¸­çŠ¶æ€
                    async with self.target_update_lock:
                        for table_info in tables_dict.values():
                            if not table_info.target_updating:
                                table_info.target_updating = True
                                self.log(f"ç›®æ ‡è¡¨ {table_info.target_table_name} å¼€å§‹æ›´æ–°")

                    # ç„¶åé€ä¸ªå¤„ç†è¡¨
                    for target_table_name, table_info in tables_dict.items():
                        # æ£€æŸ¥åœæ­¢æ ‡å¿—
                        if self.stop_event.is_set():
                            # æ¢å¤æ‰€æœ‰è¡¨çš„çŠ¶æ€
                            async with self.target_update_lock:
                                for ti in tables_dict.values():
                                    ti.target_updating = False
                            return False

                        # åœ¨é”å¤–æ‰§è¡ŒæŸ¥è¯¢ä»¥é¿å…é•¿æ—¶é—´é”å®š
                        try:
                            # ç›´æ¥è·å–ç›®æ ‡è¡¨çš„è®°å½•æ•°
                            new_count = 0
                            async with target_conn.cursor() as cursor:
                                await cursor.execute(f"SELECT COUNT(*) FROM `{schema_name}`.`{target_table_name}`")
                                result = await cursor.fetchone()
                                if result:
                                    new_count = result[0]

                            # æŸ¥è¯¢å®Œæˆåæ›´æ–°ç»“æœ
                            async with self.target_update_lock:
                                if not table_info.is_first_query:
                                    table_info.previous_target_rows = table_info.target_rows
                                else:
                                    table_info.previous_target_rows = new_count
                                    table_info.is_first_query = False

                                table_info.target_rows = new_count
                                table_info.target_last_updated = current_time
                                table_info.target_updating = False
                                table_info.target_is_estimated = False  # æ ‡è®°ä¸ºç²¾ç¡®å€¼
                                self.log(f"ç›®æ ‡è¡¨ {table_info.target_table_name} æ›´æ–°å®Œæˆï¼Œè¡Œæ•°: {new_count}")

                                # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸€è‡´ï¼Œå¦‚æœä¸€è‡´åˆ™æš‚åœè‡ªåŠ¨åˆ·æ–°
                                if table_info.is_consistent:
                                    table_info.pause_auto_refresh = True
                                    self.log(f"è¡¨ {table_info.target_table_name} æ•°æ®ä¸€è‡´ï¼Œæš‚åœè‡ªåŠ¨åˆ·æ–°")

                        except Exception as e:
                            # å‡ºç°å¼‚å¸¸æ—¶æ ‡è®°ä¸ºé”™è¯¯çŠ¶æ€
                            async with self.target_update_lock:
                                if not table_info.is_first_query:
                                    table_info.previous_target_rows = table_info.target_rows
                                else:
                                    table_info.previous_target_rows = -1
                                    table_info.is_first_query = False

                                table_info.target_rows = -1  # -1è¡¨ç¤ºæŸ¥è¯¢å¤±è´¥
                                table_info.target_last_updated = current_time
                                table_info.target_is_estimated = False  # é”™è¯¯çŠ¶æ€ä¸æ˜¯ä¼°è®¡å€¼

                return True
            finally:
                target_conn.close()

        except Exception as e:
            # å‡ºç°å¼‚å¸¸æ—¶ï¼Œæ ‡è®°æ‰€æœ‰è¡¨çš„target_updatingä¸ºFalse
            async with self.target_update_lock:
                for table_info in tables_dict.values():
                    if table_info.target_updating:
                        table_info.target_updating = False
            return False

    async def update_target_counts(self, conn, target_tables: Dict[str, Dict[str, TableInfo]]):
        """æ›´æ–°ç›®æ ‡MySQLè®°å½•æ•°ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œç”¨äºå…¼å®¹æ€§ï¼‰"""
        for schema_name, tables_dict in target_tables.items():
            await self._update_single_schema_target(schema_name, tables_dict, use_information_schema=False)

    async def update_target_counts_async(self, target_tables: Dict[str, Dict[str, TableInfo]]):
        """å¼‚æ­¥æ›´æ–°ç›®æ ‡MySQLè®°å½•æ•°ï¼ˆä¸é˜»å¡ä¸»çº¿ç¨‹ï¼‰"""
        # æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
        self.target_update_tasks = [f for f in self.target_update_tasks if not f.done()]

        # ä¸ºæ¯ä¸ªschemaæäº¤å¼‚æ­¥æ›´æ–°ä»»åŠ¡
        for schema_name, tables_dict in target_tables.items():
            # æ£€æŸ¥è¯¥schemaæ˜¯å¦å·²ç»æœ‰æ­£åœ¨è¿›è¡Œçš„æ›´æ–°ä»»åŠ¡
            schema_updating = False
            async with self.target_update_lock:
                for table_info in tables_dict.values():
                    if table_info.target_updating:
                        schema_updating = True
                        break

            if not schema_updating:
                future = asyncio.create_task(
                    self._update_single_schema_target(schema_name, tables_dict, use_information_schema=False))
                self.target_update_tasks.append(future)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="MySQL vs MySQL æ•°æ®ä¸€è‡´æ€§ç›‘æ§å·¥å…· (Textualç‰ˆæœ¬ï¼Œæ”¯æŒè¡¨æ˜ å°„å…³ç³»)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python3 app.py                          # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ•°æ®åº“åˆ—è¡¨
  python3 app.py --databases db1,db2     # ç›‘æ§æŒ‡å®šçš„æ•°æ®åº“
  python3 app.py -d test_db               # åªç›‘æ§test_dbæ•°æ®åº“
  python3 app.py --config my_config.ini  # ä½¿ç”¨æŒ‡å®šçš„é…ç½®æ–‡ä»¶

å¿«æ·é”®:
  q/Ctrl+C : é€€å‡ºç¨‹åº
  r        : æ‰‹åŠ¨åˆ·æ–°æ•°æ®
  space    : æš‚åœ/ç»§ç»­ç›‘æ§
  s        : åˆ‡æ¢æ’åºæ–¹å¼ (Schema.è¡¨å â†’ æ•°æ®å·®å¼‚ â†’ ç›®æ ‡è®°å½•æ•° â†’ æºè®°å½•æ•°)
  f        : åˆ‡æ¢è¿‡æ»¤æ–¹å¼ (å…¨éƒ¨ â†’ ä¸ä¸€è‡´ â†’ ä¸€è‡´ â†’ é”™è¯¯)
  æ–¹å‘é”®   : ç§»åŠ¨å…‰æ ‡æµè§ˆè¡¨æ ¼
  Page Up/Down : å¿«é€Ÿç¿»é¡µ
        """
    )

    parser.add_argument(
        '--databases', '-d',
        type=str,
        help='æŒ‡å®šè¦ç›‘æ§çš„MySQLæ•°æ®åº“åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„databasesé…ç½®'
    )

    parser.add_argument(
        '--config', '-c',
        type=str,
        default="config.ini",
        help='æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: config.iniï¼‰'
    )

    args = parser.parse_args()

    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    config_file = args.config
    if not Path(config_file).exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        print("è¯·ç¡®ä¿config.iniæ–‡ä»¶å­˜åœ¨å¹¶é…ç½®æ­£ç¡®")
        sys.exit(1)

    # å¤„ç†æ•°æ®åº“åˆ—è¡¨å‚æ•°
    override_databases = None
    if args.databases:
        override_databases = [db.strip() for db in args.databases.split(',') if db.strip()]
        if not override_databases:
            print("âŒ æŒ‡å®šçš„æ•°æ®åº“åˆ—è¡¨ä¸ºç©º")
            sys.exit(1)

    app = MonitorApp(config_file, override_databases)
    app.run()


if __name__ == "__main__":
    main()
